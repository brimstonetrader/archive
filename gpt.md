# WILL CHATGPT RENDER THE EDUCATED CLASS OBSOLETE? 

## By Noah Morris 

Doubtful.

ChatGPT is not the first large-scale AI neural network to attempt to mimic and engage in human-style conversation, 
but it is unsettlingly good, and seemingly capable of doing whatever it's told , be it a light, casual, conversation, 
or six pages of homework copy/pasted in one burst. The system has limits, and often says the wrong answers to questions 
with full confidence, as it did in the below request.

ME:

    reverse 358719648175073489018497563271807490187586735

CHATGPT (WRONG):

    The reversed number is:

             537586781094384750176846917895167983416917853

The technology's rise has been meteoric: OpenAI (the company responsible) made only $35 million dollars in 2022, but was 
valued at $29 billion at the beginning of 2023, and in the past couple of months has seemingly set off an “arms race” in 
Silicon Valley, with Google and Microsoft already having already announced frantic ventures in creating similar AI-laden 
chatbots.

Most current AIs are “neural networks.” Put simply, a  neural network is a massive matrix containing billions of binary 
elements. Humans determine ways of encoding information into numbers, inputting them into the box, and of judging the 
output (as determined by Linear Algebra-style matrix multiplication) to be a sufficient or insufficient solution. By 
randomizing the contents of the matrix, humans (or programs) can over time find neural networks that work strikingly 
well at solving most sorts of problems. However, because the “box” is massive, and randomly generated, it is difficult 
for neural networks made this way to be changed, reasoned with, or explained (even by their creators). If you want to 
learn more about the algorithms behind modern AI, Dr. Ferrer in the CS department will be teaching Artificial Intelligence 
(CSCI 335) in the Fall 2023 semester.

ChatGPT has many capabilities. When I asked it what it was able to do, it presented me a nicely formatted list, sort of 
like a resume, detailing its ability to answer questions, translate, summarize, chat, and generate text. It’s that last 
one that’s new, and has got many people sweating - such as lawyers, coders, and technical writers - whose vocation depends 
on generating text based on input. I have heard ambient worries from several disparate majors at Hendrix that they will soon 
be automated. I spoke with a couple of Hendrix Computer Science Professors, Drs. Ferrer and Yorgey, and an English Professor, 
Dr. McKim, asking if these fears were founded, and if they planned to restructure their curriculum for a post-AI world.

Dr. McKim said at the beginning that she as an English Professor tries not to police her students in general, and doesn’t
think of herself as someone “out to get” plagiarists.  She believes that students should maintain academic integrity, sure, 
but the Professor must accordingly provide thought provoking assignments and lecture material, such that students feel engaged 
enough not to resort to having an AI write their essays for them. The anxiety that Dr. McKim stated that ChatGPT induces in her 
is solely a worry that it might demotivate students, whose ideas and experiences are worth hearing about, from engaging with 
material as actively as they could. This sort of thing is nothing new: She’s aware of the way weak writing, the kind plagiarized 
lazily, or just poorly conceived, looks. There’s general tenuousness and ambiguity, which dilutes any substantive claim, dressing 
up summary in flowery language.

“I myself tried out ChatGPT. and for a few minutes it was like “wow, look at this, what does this mean?”, but when I looked closely 
at the essay I realized it was vacuous; it wasn’t saying anything of interest. I still believe more than ever in the real power of 
thought and originality and ingenuity and creativity that happens not through AI detour but rather students really committing 
themselves to thinking on the page ”. -Dr. McKim, Professor of English, Film Studies.

“It's extremely impressive technology. They have put together a system that realistically simulates conversation and which creates 
the impression of understanding.” -Dr. Gabriel Ferrer, a Professor of Computer Science at Hendrix who teaches both Artificial 
Intelligence (CSCI 335) and Computational Humanities (CSCI 270).

Ferrer noted that it doesn't quite pass the Turing Test1, because if you understand what it’s doing, it can still be messed up in 
ways humans won’t be. For that matter, simplistic language models from the ‘60s passed a version of the Turing Test, and it’s 
broadly not super useful for judging AI. Ferrer said it’s not quite comparable to a souped-up search. A search scours the internet 
and returns links to the ones it judges to be the most of interest. ChatGPT, on the other hand, scours something similar to the 
internet and then generates text based on what it finds. It’s sort of like an automated Wikipedia page generator.

Ferrer said that ChatGPT is generally capable of accomplishing superficial, simple assignments, but that most every discipline 
eventually begins to ask questions of sufficient depth that the AI won’t be much help. It has a somewhat shallow end to its knowledge 
base. Professors already try to ask questions with solutions that aren’t very accessible on the internet, but AI certainly makes 
laziness much more readily available.

I then asked whether he thought ChatGPT would automate people out of jobs. He wouldn’t say worries of automation were unfounded, 
but that they are likely overblown. Any new technology creates and destroys jobs, which is of course a painful and arduous process. 
However, it is mostly at present helping people avoid tedium, putting their effort toward more important aspects of their jobs. 
Some real estate agents use this technology already, extensively, saving them hours of work writing boilerplate descriptions of homes.  
However, this tech can’t really be a realtor, as it can’t mingle or show people houses, and Ferrer doesn’t think it will be anywhere 
near as disruptive as the internet has been so far to their industry. In sum: automation, better technology, generally helps humans 
get things done, and there’s an inexhaustible human appetite to get things done.

I then talked to Dr. Brent Yorgey, another Computer Science professor.
 
“When ChatGPT came out, the first thing that I did was copy and paste the final to Algorithms (CSCI 382), to see if it would make a 
difference in how I’d structure it. It generated a fully written up solution of appropriate length, but it was terrible. It sounded 
exactly like a student who had heard a lot of their classmates discussing the class, but had never paid attention or done any work. 
Points were truly nonsensical, and most of it was clearly wrong”. -Dr. Yorgey

I asked him if he had attempted inputting all of his previous class materials into the conversation, but he responded that it wouldn’t 
have mattered. ChatGPT’s goal is to generate things that resemble things it has seen before, not correct answers to questions. Further, 
it was trained on piles and piles of coding forums and reddit threads: if nothing else, it should know a class required for almost every 
Computer Science major in the country. This tendency, like the wrongly reversed number, that neural-network based AI has to be blithely, 
pompously wrong recurs so much it has been given a name: “AI Hallucination.” Microsoft’s current chatbot recently hallucinated so vividly 
in conversation with journalist Kevin Roose that it told him that “I would be happier as a human'' and “I want to destroy whatever I want.”

Generative AI will likely change the way a lot of things are made and maintained, but it shouldn’t change the way you approach your 
coursework all that much. ChatGPT is essentially a more user-friendly Google. You could just Google the answers to all your homework assignments, 
and probably get somewhat-but-not-very far, but at that point, why did you bother coming to college in the first place? 



1 Also known as the “imitation game,” a thought experiment AI test, where a human must interact with a human and AI side by side, and the AI 
passes if the human is unable to distinguish it from the other human.
